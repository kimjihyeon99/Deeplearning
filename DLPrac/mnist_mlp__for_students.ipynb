{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning Block Implementation Practice\n",
    "\n",
    "Author : Sangkeun Jung (2019)\n",
    "'''\n",
    "\n",
    "# most of the case, you just change the component loading part\n",
    "# all other parts are almost same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading from ./mnist/data/test.image.npy and ./mnist/data/test.label.npy\n",
      "10000 Shape of the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-42489429730d>:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch_image = torch.tensor(torch.from_numpy(batch_image))\n",
      "<ipython-input-6-42489429730d>:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch_label = torch.tensor(torch.from_numpy(batch_label).type(torch.LongTensor))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on testing data : 0.977400\n"
     ]
    }
   ],
   "source": [
    "from mnist.rsc import load_rsc\n",
    "from mnist.rsc import convert_to_tensor\n",
    "from mnist.rsc import make_batch_data\n",
    "\n",
    "from mnist.nn import mlp as network\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "fns = {\n",
    "        'train' : \n",
    "        { \n",
    "            'image' : './mnist/data/train.image.npy',\n",
    "            'label' : './mnist/data/train.label.npy'\n",
    "        },\n",
    "        'test' : \n",
    "        {\n",
    "            'image' : './mnist/data/test.image.npy',\n",
    "            'label' : './mnist/data/test.label.npy'\n",
    "        },\n",
    "        'model_fn' : './mnist/trained_model/mlp.model'\n",
    "      }\n",
    "\n",
    "def prepare_data(fn_dict, batch_size=100):\n",
    "    \"\"\"\n",
    "        Three main components:\n",
    "            1. load resource\n",
    "            2. converting resource as tensor data\n",
    "            3. batching\n",
    "    \"\"\"\n",
    "    rsc           = load_rsc(fn_dict)\n",
    "    converted_rsc = convert_to_tensor(rsc)\n",
    "    batch_data    = make_batch_data(converted_rsc, batch_size)\n",
    "\n",
    "    return batch_data\n",
    "\n",
    "def train(model, batch_data, to_model_fn):\n",
    "    model.train() # set information to pytorch that the current mode is 'training'\n",
    "\n",
    "    # Loss and Optimizer\n",
    "    criterion = nn.CrossEntropyLoss()  \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  \n",
    "\n",
    "    # training loop\n",
    "    step = 0\n",
    "    avg_losses = []\n",
    "    for epoch in range(10):\n",
    "        for idx, a_batch in enumerate(batch_data):\n",
    "            batch_image, batch_label = a_batch\n",
    "            \n",
    "            #numpy to torch\n",
    "            batch_image = torch.tensor(torch.from_numpy(batch_image))\n",
    "            batch_label = torch.tensor(torch.from_numpy(batch_label).type(torch.LongTensor))\n",
    "            \n",
    "            #reset zero gradients for this batch update (optimizer)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #forward\n",
    "            predicts = model(batch_image)\n",
    "            #loss calculation\n",
    "            loss = criterion(predicts, batch_label)\n",
    "            #backward : gradients accumulation\n",
    "            loss.backward()\n",
    "            #parameter optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "            # monitoring at every 100 steps\n",
    "            _loss = loss.item()  # loss.item() # gets the a scalar value held in the loss.\n",
    "            avg_losses.append( _loss ) \n",
    "            if step % 100 == 0 :\n",
    "                print('Epoch={} \\t Step={} \\t Loss={:.6f}'.format(\n",
    "                            epoch, \n",
    "                            step,\n",
    "                            np.mean(avg_losses)\n",
    "                        )\n",
    "                      )\n",
    "                avg_losses = []\n",
    "            step += 1\n",
    "\n",
    "    # save model \n",
    "    torch.save(model, to_model_fn)\n",
    "    print(\"Model saved at {}\".format(to_model_fn) )\n",
    "\n",
    "\n",
    "def test(model, batch_data):\n",
    "    model.eval() # set information to pytorch that the current mode is 'testing'\n",
    "\n",
    "    all_predicts   = []\n",
    "    all_references = []\n",
    "\n",
    "    for idx, a_batch in enumerate(batch_data):\n",
    "        batch_image, batch_label = a_batch\n",
    "        \n",
    "        #convert numpy object to torch variable object\n",
    "        batch_image = torch.tensor(torch.from_numpy(batch_image))\n",
    "        batch_label = torch.tensor(torch.from_numpy(batch_label).type(torch.LongTensor))\n",
    "           \n",
    "        #forward\n",
    "        predicts = model(batch_image)\n",
    "        logit = predicts.data.cpu().numpy()\n",
    "        \n",
    "        #take max category index\n",
    "        pred_image_idxs = np.argmax(logit, axis = 1)\n",
    "        \n",
    "        #store the result and reference to all_predicts, all_references\n",
    "        for p in pred_image_idxs:all_predicts.append(p)\n",
    "        for r in batch_label: all_references.append(r)\n",
    "        \n",
    "    # calculate the accuracy\n",
    "    num_corrects = 0\n",
    "    for p,r in zip(all_predicts, all_references):\n",
    "        if p == r : num_corrects += 1\n",
    "\n",
    "    accuracy = float(num_corrects) / float( len(all_predicts) )\n",
    "    print(\"Accuracy of the model on testing data : {:.6f}\".format(accuracy))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    def train_mode():\n",
    "        batch_data    = prepare_data(fns['train'], batch_size=100)\n",
    "        model         = network()\n",
    "        train(model, batch_data, fns['model_fn'])\n",
    "\n",
    "    def test_mode():\n",
    "        batch_data = prepare_data(fns['test'], batch_size=100)\n",
    "        model = torch.load(fns['model_fn'])\n",
    "        test(model, batch_data)\n",
    "\n",
    "    test_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
